---
title: "Boosted trees"
subtitle: "Series 2.3.1 - Adaptive boosting"
author: Jennifer HY Lin
date: '2024-4-17'
draft: true
categories: 
    - Machine learning projects
    - Tree models
    - Pandas
    - Scikit-learn
    - RDKit
    - ChEMBL database
    - Python
jupyter: python3
format: html
bibliography: references.bib
---

##### **Some introductions**

Adaptive Boost is also known as AdaBoost, which has originated from Robert E. Schapire in 1990 [@schapire1990], [@mlbook2022]. This concept was further introduced in 1996 by Robert Schapire and Yoav Freund at a conference and led to another publication [@freund1997].

Can be used for classification or regression problems.

"...fit a sequence of weak learners (i.e., models that are only slightly better than random guessing, such as small decision trees) on repeatedly modified versions of the data." (quoted from scikit-learn - https://scikit-learn.org/stable/modules/ensemble.html#adaboost)

-   Increased weights are given to incorrectly predicted samples by the AdaBoost models at each iteration. Conversely, less weights are given to the correctly predicted ones. Overall, this forces the AdaBoost model to focus more on the less accurately predicted samples. In the end, the prediction from these iterations are combined to produce a final prediction via a weighted majority vote style (signature of tree models).

Parameters to tune:

n_estimators (number of weak learners)

learning_rate (contributions of weak learners in the final combination)

max_depth (depth)

min_samples_split (minimum required number of samples to consider a split)

```{python}
import sys
import pandas as pd
import numpy as np

from sklearn.ensemble import AdaBoostRegressor
```

```{python}
# Show system info
print(sys.version)
```

```{python}
# Reading from the previously saved file
df_ache = pd.read_csv("chembl_d_ache_33.tsv", sep = ",")
```

```{python}
print(df_ache.shape)
df_ache.head()
```

Some simple data explorations

```{python}
df_ache.value_counts("max_phase")
```

```{python}
df_ache.value_counts("pchembl_value")
```

```{python}
df_ache[["pchembl_value"]].describe()
```

Decide what training data to use for targets e.g. fingerprints or RDKit 2D descriptors or others

AdaBoost regressor (target: pchembl_value) or classifier (target: max_phase)
