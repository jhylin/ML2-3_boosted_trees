---
title: "Boosted trees"
subtitle: "Series 2.3"
author: Jennifer HY Lin
date: '2024-4-15'
draft: true
categories: 
    - Machine learning projects
    - Tree models
    - Pandas
    - Scikit-learn
    - RDKit
    - ChEMBL database
    - Python
jupyter: python3
format: html
bibliography: references.bib
---

*Planning stage - Feb - Apr 2024*


*Datasets - searching for other ways of obtaining public drug discovery datasets (?separate post by itself)*
Options:
- ChEMBL dataset obtained previously via chembl_downloader
- Biogen (ADMET data) or activity cliff paper


*AdaBoost* (1st post)


*LightGBM* (2nd post)
* Developed by Microsoft

Scikit-learn has built-in functions
* Histogram-based gradient boosting
- Mainly inspired by LightGBM
- Supports missing values and categorical data
- HistGradientBoostingClassifier() or regressor - best for sample size > tens of thousands
- GradientBoostingClassifier() or regressor - for small sample size e.g. < tens of thousands


*XGBoost* (3rd post)
* Using stochastic gradient boosting
* Parameters to tune: 
- subsample - controls fraction of observations that should be sampled at each iteration
- eta (or learning-rate in scikit-learn) - shrinkage factor applied to alpha in the boosting algorithm