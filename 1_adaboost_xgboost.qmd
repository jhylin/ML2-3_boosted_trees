---
title: "Boosted trees"
subtitle: "Series 2.3.1 - AdaBoost, XGBoost and Scikit-mol"
author: Jennifer HY Lin
date: '2024-5-29'
draft: true
categories: 
    - Machine learning projects
    - Tree models
    - Pandas
    - Scikit-learn
    - RDKit
    - ChEMBL database
    - Python
jupyter: python3
format: html
bibliography: references.bib
---

##### **Some introductions**

I've somehow promised myself to do a tree series on machine learning and glad I've made it to the boosted trees part (it took a while...). This is also likely my last post on this topic for now as there are other things I want to explore in the near future. Hopefully this is somewhat useful for anyone who's new to this.

<br>

###### **AdaBoost**

Adaptive Boost or AdaBoost has originated from Robert E. Schapire in 1990 [@schapire1990], [@mlbook2022], and was further introduced in 1996 by Robert Schapire and Yoav Freund at a conference which also led to a publication [@freund1997].

As quoted from [scikit-learn](https://scikit-learn.org/stable/modules/ensemble.html#adaboost), an AdaBoost algorithm is doing this:

> ...fit a sequence of weak learners (i.e., models that are only slightly better than random guessing, such as small decision trees) on repeatedly modified versions of the data.

::: {.callout-note}
Weak learner means an ensemble of very simple base classifiers such as decision tree stumps [@mlbook2022]
:::

During the process of running the algorithm, increased weights are given to the incorrectly predicted samples at each iteration, and less weights are given to the correctly predicted ones. This then forces the AdaBoost models to focus more on the less accurately predicted samples with the aim to improve ensemble performance. The predictions from these iterations are combined to produce a final prediction via a weighted majority vote style, which is a well-known signature of tree models. Overall, AdaBoost algorithm can be used for classification or regression problems. The main difference between bagging and boosting is that boosting only uses random subsets of training samples drawn from the training dataset without any replacements [@mlbook2022]. One caveat to note is that AdaBoost tend to overfit training data (high variance).

Parameters to tune:

* *n_estimators* - number of weak learners

* *learning_rate* - contributions of weak learners in the final combination

* *max_depth* - depth of trees

* *min_samples_split* - minimum required number of samples to consider a split

<br>

###### **Gradient boosted trees**

Essentially a similar concept is behind gradient boosted trees where a series of weak learners is trained in order to create a stronger ensemble of models [@mlbook2022]. However, some differences between these two types of boosted trees (e.g. AdaBoost and XGBoost) should be noted, and rather than describing them in a paragraph, I've summarised them in a table below.

```{python}
#| echo: false
#| tbl-cap-location: margin
#| tbl-cap: Differences between XGBoost and AdaBoost [@mlbook2022]


from IPython.display import Markdown
from tabulate import tabulate

table = [
    ["trains weak learners based on errors from previous decision tree stump", 
    "trains weak learners that are deeper than decision tree stumps with a max depth of 3 to 6 (or max number of leaf nodes from 8 to 64)"], 
    ["uses prediction errors to calculate sample weights and classifier weights", 
    "uses prediction errors directly to produce the target variable to fit the next tree"], 
    ["uses individual weighting terms for each tree", 
    "uses a global learning rate for each tree"]
    ]

Markdown(tabulate(table, headers=["AdaBoost", "XGBoost"]))
```

XGBoost or extreme gradient boosting [@DBLP:journals/corr/ChenG16] is one of the most commonly used open-source packages, originally developed at the University of Washington by T. Chen and C. Guestrin, that uses stochastic gradient boosting to build an ensemble of predictive models. 

[XGBoost documentation](https://xgboost.readthedocs.io/en/stable/index.html) - https://xgboost.readthedocs.io/en/stable/index.html

Main parameters to tune as suggested by [@bruce2020]: 

- *subsample* - controls fraction of observations that should be sampled at each iteration or a subsample ratio of the training instance (as per [XGBoost's Scikit-learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)). This is similar to how a random forest operates but without the sample replacement part

- *eta* (in XGBoost) or *learning_rate* (in scikit-learn wrapper interface for XGBoost) - a shrinkage factor applied to alpha (a factor derived from weighted errors) in the boosting algorithm or it simply may be more easily understood as the boosting learning rate used to prevent overfitting

There are of course a whole bunch of other [XGBoost parameters](https://xgboost.readthedocs.io/en/latest/parameter.html#xgboost-parameters) that can be tuned, and in order to keep this post at a reasonable reading length, I won't go through every single one of them, but see this link as an example parameter set for [XGBClassifier()](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier).

In scikit-learn, there are also two types of gradient boosted tree methods, GradientBoostingClassifer() and HistGradientBoostingClassifier(), in its sklearn.ensemble module (note: equivalent regressor class also available). One way to choose between them is to check sample size first. [GradientBoostingClassifer()](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier) class is likely better when there is only a small sample size (e.g. when number of sample is less than 10,000), while [HistGradientBoostingClassifier()](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html#sklearn.ensemble.HistGradientBoostingClassifier) class is likely better when your sample size is at least 10,000+ or more. The HistGradientBoostingClassifier() is a histogram-based gradient boosting classification tree that is mainly inpired by [LightGBM](https://github.com/Microsoft/LightGBM). 

<br>

##### **A demo**

In the example below, I'm only using AdaBoostClassifier() and XGBClassifier() for now. Please note that the dataset used here is very small and the example is likely not going to reflect real-life use case completely (use with care). 

<br>

###### **Import libraries**

```{python}
import sys
import pandas as pd
import numpy as np
import chembl_downloader

from rdkit import Chem

# Import Scikit_mol
## Check and clean SMILES
from scikit_mol.utilities import CheckSmilesSanitazion
## Standardise molecules
from scikit_mol.standardizer import Standardizer
## Import fingerprints & descriptors
from scikit_mol.fingerprints import MorganFingerprintTransformer
from scikit_mol.descriptors import MolecularDescriptorTransformer
## Import smi2mol transformer
from scikit_mol.conversions import SmilesToMolTransformer

# Import scikit-learn
import sklearn
from sklearn.model_selection import train_test_split
## Data scaler (variance scaling)
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier

# Import xgboost classifier
import xgboost
from xgboost import XGBClassifier

print(f"xgboost version used: {xgboost.__version__}\nscikit-learn version used: {sklearn.__version__}")
```

```{python}
# Show Python version used 
print(sys.version)
```

<br>

###### **Data source**

Data source is based on ChEMBL database version 33 (as shown by the file name below, "chembl_d_ache_33"), which was downloaded previously from last post (on [random forest classifier](https://jhylin.github.io/Data_in_life_blog/posts/17_ML2-2_Random_forest/2_random_forest_classifier.html)) by using [chembl_downloader](https://github.com/cthoyt/chembl-downloader).

```{python}
from pathlib import Path

# Pick any directory, but make sure it's relative to your home directory
directory = Path.home().joinpath(".data", "blog")
# Create the directory if it doesn't exist
directory.mkdir(exist_ok=True, parents=True)

# Create a file path that corresponds to the previously cached ChEMBL data 
path = directory.joinpath(f"chembl_d_ache_33.tsv")

# alternative way to download latest ChEMBL version
# please see post link - https://jhylin.github.io/Data_in_life_blog/posts/17_ML2-2_Random_forest/2_random_forest_classifier.html#data-retrieval-using-chembl_downloader for details
# note: need to specify late_version = latest() first
# path = directory.joinpath(f"chembl_d_ache_{latest_version}.tsv")

if path.is_file():
    # If the file already exists, load it
    df_ache = pd.read_csv(path, sep=',')
else:
    # If the file doesn't already exist, make the query then cache it
    df_ache = chembl_downloader.query(sql)
    df_ache.to_csv(path, sep=",", index=False)
```

```{python}
print(df_ache.shape)
df_ache.head()
```

Exploring max phases of compounds in the dataset.

```{python}
df_ache.value_counts("max_phase")
```

<br>

###### **Dealing with data labelled "nan"**

The [definition of "nan" assigned to max_phase](https://chembl.gitbook.io/chembl-interface-documentation/frequently-asked-questions/drug-and-compound-questions#what-is-max-phase) indicated that compounds labelled as "nan" or "null" had no evidence showing they've reached clinical trials, so it would probably (depend on project goals) be the best to remove them from the dataset.

Removing all "NaN" or "null" compounds in max_phase (target y variable) column.

```{python}
df_ache.dropna(axis="index", subset=["max_phase"], inplace=True)
```

Check for any "NaNs" in the canonical SMILES column (X variable), since AdaBoostClassifier won't accept missing values in the dataset, but the HistGradientBoostingClassifier() (or the regressor) should take care of the native NaNs. There are other ways to deal with NaNs with a few examples provided by [scikit-learn](https://scikit-learn.org/stable/modules/impute.html). With regards to drug discovery data, there might be more caveats that need to be taken during data preprocessing (I'm also exploring this too). Since this is a simple demonstration only, I'll use the most basic strategy which is removing the whole row of data if any NaN is found within the X or y variables. The downside of this basic way of dealing with missing data is that you may end up losing some potentially useful or valuable data.

```{python}
# Suspected there might be missing SMILES earlier, but tested with an alternative method by running through mol_prep.py, and it went through without problems by generating RDKit mols. So commented off following code re. canonical_smiles

# df_ache["canonical_smiles"].describe()

#df_ache.value_counts("canonical_smiles")

# df_ache["canonical_smiles"].fillna("null", inplace=True)

# df_ache["canonical_smiles"] != "null"

# df_ache.drop_duplicates(subset=["canonical_smiles"], inplace=True)

# df_ache["canonical_smiles"].describe()
```

```{python}
print(df_ache.shape)
df_ache.head()
```

Dataframe reduced to 734 rows only.

```{python}
df_ache[["max_phase"]].value_counts()
```

A max_phase of -1 is assigned with an unknown clinical phase status ([ChEMBL reference](https://chembl.gitbook.io/chembl-interface-documentation/frequently-asked-questions/drug-and-compound-questions#what-is-max-phase)), which I'm going to drop for this particular experiment.

```{python}
# Select only mols with max_phase of 0.5 and above
df_ache = df_ache[(df_ache["max_phase"] >= 1)]
```

```{python}
df_ache["max_phase"].describe()
```

```{python}
df_ache["max_phase"].value_counts()
```

```{python}
df_ache.dtypes
```

```{python}
# df_ache = df_ache.convert_dtypes().dtypes
```

```{python}
# Convert max_phase from float to int
df_ache = df_ache.astype({"max_phase": int, "canonical_smiles": "string"})
```

```{python}
df_ache.dtypes
```

<br>

##### **Model building using scikit-learn's pipeline**

Likely model forming steps:

1. Determine whether to use binary or multi-class classification

    Previously used binary classification, e.g. target as max_phase 4 ("1") and used max_phase of "null" as "0".

    This time likely trying out multi-class classification to predict max_phase which contains 0.5, 1, 2, 3, 4.


2. Define X, y

```{python}
df_ache
```

```{python}
X = df_ache.canonical_smiles
y = df_ache.max_phase
```

```{python}
X
```


```{python}
X.shape
```

```{python}
y.shape
```

```{python}
print(X)
```

```{python}
print(y)
```


3. SMILES sanitisation

    This post is likely going to focus only on Scikit_mol which has a different way to handle SMILES errors. Another useful way to deal with SMILES errors is molpipeline's SMILES error handling, with an example shown in one of its notebooks - https://github.com/basf/MolPipeline/blob/main/notebooks/03_error_handling.ipynb. The main difference from what I could see was that molpipeline takes into account all the invalid SMILES by giving each invalid SMILES a "nan" label in the pipeline process - this maintains the matrix shape and good for tracking down the problematic SMILES (compounds).

```{python}
checksmi = CheckSmilesSanitazion()
# Checking on SMILES (X) only 
X_valid, X_errors = checksmi.sanitize(X)
```

Ideally will be using X_valid & y_valid for further work (but this also means removing the invalids or errors completely from the training dataset). Another similar package, molpipeline - https://github.com/basf/MolPipeline might be of some use here, where its special feature is handling errors within the pipeline.

```{python}
checksmi.errors
```

No SMILES errors shown.

```{python}
X_errors
```

Showed no outputs (no errors detected). 

```{python}
print(X_valid)
```

Generated a list of valid SMILES.

```{python}
# Check if there's any NaNs in canonical_smiles column
print(f"{df_ache.canonical_smiles.isna().sum()} out of {len(df_ache)} SMILES failed in conversion")
```

4. Data splitting

    Randomly splitting data this time.

```{python}
# X = X.to_numpy()
# y = y.to_numpy()
```

```{python}
# type(X)
```

```{python}
# Found a silly error when naming X, y train/test sets!
# X_train, X_test, y_train, y_test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)
```

5. Create a pipeline using scikit-learn

    Choosing data features for targets such as fingerprints (e.g. Morgan fingerprints best for larger dataset) or RDKit 2D descriptors (useful for smaller datasets) or others

    *[Useful Jupyter notebook](https://github.com/EBjerrum/scikit-mol/blob/main/notebooks/07_parallel_transforms.ipynb) explaining when to best use parallel calculations to calculate molecular fingerprints and descriptors*

    AdaBoost classifier (target: max_phase)
    (likely not going to use regressor which uses pchembl_value, which is the -log of published activity values e.g. IC50 - [ChEMBL database link](https://chembl.gitbook.io/chembl-interface-documentation/frequently-asked-questions/chembl-data-questions#what-is-pchembl) that explains this)

    Possibly chaining AdaBoostClassifier(), XGBClassifier(), along with Scikit-mol transformers

    Links re. building pipeline in scikit-learn:

    - [Pipeline module](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn-pipeline-pipeline)

    - [make_pipeline module](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn-pipeline-make-pipeline) (simpler pipeline construction, without naming estimators ourselves but rather naming them automatically)

```{python}
# descriptor = MolecularDescriptorTransformer()
# available_descriptors = descriptor.available_descriptors
# print(f"There are {len(available_descriptors)} available descriptors")
# print(f"The first five descriptor names: {available_descriptors[:5]}")

rdkit2d = MolecularDescriptorTransformer()
available_descriptors = rdkit2d.available_descriptors
print(f"First 10 descriptor names: {available_descriptors[:10]}")
```

---Original pipeline---

```{python}
# params_rdkit2d = {
#     "desc_list":
# }

# Set parameters for adaboost model
params_adaboost = {
    "estimator": DecisionTreeClassifier(max_depth = 3), 
    # default: n_estimators = 50, learning_rate = 1.0 (trade-off between them)
    "n_estimators": 80, 
    "learning_rate": 0.2, 
    # SAMME (Stagewise Additive Modeling using a Multi-class Exponential loss function) algorithm 
    # for multi-class classification
    "algorithm": "SAMME", 
    "random_state": 2,
    }

# Set parameters for xgboost model
# For multi-class classification, use softprob for loss function
# https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters
# params_xgboost = {
#     "n_estimators": 100,
#     "max_depth": 3,
#     "objective": 'multi:softprob', 
#     "learning_rate": 0.1, 
#     "subsample": 0.5, 
#     "random_state": 2
#     }

# Building pipeline
mlpipe = make_pipeline(
    # Convert SMILES to RDKit molecules
    SmilesToMolTransformer(), 

    # Molecule standardisations
    Standardizer(),

    # Generate RDKit2D descriptors (or MorganFingerprintTransformer()) for each molecule
    #MorganFingerprintTransformer(),

    MolecularDescriptorTransformer(desc_list=['HeavyAtomCount', 'FractionCSP3', 'RingCount', 'MolLogP', 'MolWt']),
    # desc_list=['HeavyAtomCount', 'FractionCSP3', 'RingCount', 'MolLogP', 'MolWt']

    # Scale variances in descriptor data
    # StandardScaler(),

    # Apply adaptive boost classifier
    # **params_adaboost
    AdaBoostClassifier(**params_adaboost)
    # Try applying xgboost classifier
    # XGBClassifier(**params_xgboost)
)
```


---Testing a molecule feature pipeline---


Generated an error message:

****
Pre-condition Violation
RingInfo not initialized
Violation occurred on line 129 in file /Users/runner/work/rdkit-pypi/rdkit-pypi/build/temp.macosx-10.9-x86_64-cpython-311/rdkit/Code/GraphMol/RingInfo.cpp
Failed Expression: df_init
****

```{python}
# Generate a molecule feature pipeline
# desc_pipe = make_pipeline(
#     SmilesToMolTransformer(),
#     Standardizer(),
#     #MorganFingerprintTransformer(),
#     MolecularDescriptorTransformer(desc_list=['HeavyAtomCount', 'FractionCSP3', 'RingCount', 'MolLogP', 'MolWt']),
# )
# desc_pipe.set_output(transform="pandas")

# mol_desc = desc_pipe.transform(X_train)
# mol_desc
```

```{python}
# mol_desc = mol_desc.to_numpy()
# mol_desc
```

```{python}
# type(mol_desc)
```



---Tests---

```{python}
# Check on SmilesToMolTransformer()
# smitomol = mlpipe.transform(X_train)
# smitomol

## appeared to have converted all cpds to RDKit mols
```

```{python}
# Check on Standardizer()
# standard = mlpipe.transform(X_train)
# standard

## appeared to have all RDKit mols standardised
```

```{python}
# type(standard)
```

```{python}
# Dissect problem using base RDKit code
# from rdkit.Chem import Descriptors


# descrs = [Descriptors.CalcMolDescriptors(mol) for mol in mols]

# df = pandas.DataFrame(descrs)

# df.head()

# df.head(3)

# desc = [Descriptors.CalcMol]

```



**Problem with cpd feature generation**

```{python}
# Test on Morgan fingerprints
#morgan = mlpipe.transform(X_train)

## Problem with ring info
```


```{python}
# Check on RDKit2D descriptors from the transformer first

# df_fingerprints = fingerprints_pipeline.transform(smis_train)
# df_fingerprints

# rdkit2d_desc = mlpipe.transform(X_train)
# rdkit2d_desc

## Problem with ring info
```

**SOLVED by realising not naming X, y train/test data correctly - Problem with "Found input variables with inconsistent numbers of samples: [531, 133]"**

Note: can't use all 209 RDKit2D descriptors for AdaBoostClassifier() as some of the descriptors will be "0" and AdaBoostClassifier() won't take care of NaNs, so using a selection of descriptors only.

6. Fit the model using the pipeline

```{python}
# Check on pipeline
mlpipe
```

```{python}
# Attempt to disable RDKit loggings - not working yet
from rdkit import RDLogger
RDLogger.DisableLog('rdApp.info')
```

```{python}
# apply the pipeline to training data
mlpipe.fit(X_train, y_train)
```

```{python}
# use the pipeline to predict on testing data
mlpipe.predict(X_test)
```

**29/5/24 - Able to use scikit_mol's transformers in scikit_learn's pipeline on AdaBoostClassifer, although there are a long list of RDKit-related error messages! Able to fit and predict on X_train, y_train & X_test data**






7. Hyperparameter tuning (*?shift to above prior to fitting model and building pipeline*)

    For XGBoost, one of the main things is to minimise model overfitting where several parameters play important roles to achieve this. For example, *learning_rate* and *subsample* are the first two mentioned previously, and another technique is based on regularisation that includes two other parameters, *reg_alpha* (L1 regularisation based on Manhattan distance) and *reg_lamda* (L2 regularisation based on Euclidean distance), which would penalise XGBoost's model complexity to make it a bit more conservative to reduce overfitting [@bruce2020].

    XGBoost contains a long list of parameters and one of the ways to find the most optimal set of parameters is by using **cross-validation**.

::: {.callout-note}
To see the default values or types of each XGBoost parameter, this XGBoost documentation [link](https://xgboost.readthedocs.io/en/latest/parameter.html#xgboost-parameters) is useful (which could be cross-referenced with XGBoost's [Python API reference](https://xgboost.readthedocs.io/en/latest/python/python_api.html#python-api-reference) when needed).
:::

```{python}
# Hyperparameter tuning - searching for most optimal set of parameters to minimise errors

#XGBoost parameters
# n_estimators
# max_depth
# learning_rate
# subsample
# reg_lambda




```

Ideally, AdaBoost is not as useful as XGBoost [@mlbook2022] in real-life use cases. 

8. Calculate metrics of the model

```{python}
# Calculate metrics of the model
```

9. Pickle to download model and parameters